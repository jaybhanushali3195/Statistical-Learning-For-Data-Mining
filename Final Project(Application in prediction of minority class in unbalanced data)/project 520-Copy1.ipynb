{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_excel('Project520test_train_data.xlsx',steet_name = 'train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    1891\n",
       " 1     609\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()\n",
    "train['y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1b76de77b38>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#checking missing data\n",
    "sns.heatmap(train.isnull(),yticklabels=False,cbar=False,cmap='viridis')\n",
    "#hence there is no missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1b76df9f908>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_style('whitegrid')\n",
    "sns.countplot(x='y',data=train,palette='RdBu_r')\n",
    "#mapping y = 1 against -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1b76e4bfe10>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#result of y with various variables\n",
    "sns.set_style('whitegrid')\n",
    "sns.countplot(x='y',hue='x2',data=train,palette='RdBu_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1b76e515b00>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_style('whitegrid')\n",
    "sns.countplot(x='y',hue='x3',data=train,palette='RdBu_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1b76e5752e8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEICAYAAABVv+9nAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAFNJJREFUeJzt3V1sU+fhx/HfibMZyEtDGlUk6oCEMjUMIYSiwEVquOhwNa3tNrGFF1FVsJe2q7tsa5cQ8gIjg0Z0kbaybm3V3ZBUGxRU9WZiLSqKKBAmJEBk7qZNbaY2zrQ0GXFs7IT47OL/Jy0l5NjEjp3H389Vc87DOT8/Sn+2npxzbNm2bQsAYJycdAcAAKQGBQ8AhqLgAcBQFDwAGIqCBwBDUfAAYCgKHgAMRcEDgKEoeAAwVG46T37x4kW53e60nDsajabt3ImYCznJmBxkTI5syBiNRrV69WrHcWkteLfbrcrKyrSc2+/3p+3ciZgLOcmYHGRMjmzI6Pf74xrHEg0AGIqCBwBDUfAAYCgKHgAMRcEDgKEoeAAwFAUPAIai4AHAUBQ8ABgqrXeyAk4iw8OKjow4jnMXFmrewoWzkAiYOyh4ZLToyIg+PHHCcdxSr5eCBz6HJRoAMBQFDwCGouABwFAUPAAYioIHAENR8ABgKAoeAAxFwQOAoSh4ADAUBQ8AhqLgAcBQFDwAGIqCBwBDxVXwn3zyidavX69//vOf6uvr05YtW7R161a1trYqFotJkg4dOqRNmzZp8+bNunz5ckpDAwCcORb8+Pi4WlpaNG/ePEnSgQMHVFdXp9dff122bevkyZPq7e3V+fPndfToUXV0dGjv3r0pDw4AmJ5jwbe3t2vz5s265557JEm9vb2qrq6WJHk8Hp05c0YXLlxQTU2NLMtSWVmZJiYmNDQ0lNrkAIBpTfuFH8ePH1dxcbEeeOABvfLKK5Ik27ZlWZYkKS8vT8FgUKOjoyoqKpr8dze2FxcXT3vyaDQqv98/09dwRyKRSNrOnYi5kDOVGd3hsAYCAcdxBYOD6g+Hb7s/2+cxWciYHLOVcdqCP3bsmCzL0tmzZ+X3+1VfX3/TJ/NQKKTCwkLl5+crFArdtL2goMDx5G63W5WVlTOIf+f8fn/azp2IuZAzlRmv9vUpWFrqOO7ukhLdtWTJbfdn+zwmCxmTY6YZ431zmHaJpqurS52dnTp8+LAqKyvV3t4uj8ejnp4eSVJ3d7eqqqq0Zs0anT59WrFYTP39/YrFYo6f3gEAqZXwd7LW19erublZHR0dqqiokNfrlcvlUlVVlWpraxWLxdTS0pKKrACABMRd8IcPH578787Ozlv2+3w++Xy+5KQCAMwYNzoBgKEoeAAwFAUPAIai4AHAUBQ8ABiKggcAQ1HwAGAoCh4ADEXBA4ChKHgAMBQFDwCGouABwFAUPAAYioIHAENR8ABgKAoeAAxFwQOAoSh4ADAUBQ8AhqLgAcBQFDwAGIqCBwBDUfAAYCgKHgAMRcEDgKEoeAAwFAUPAIai4AHAUBQ8ABiKggcAQ1HwAGAoCh4ADEXBA4ChKHgAMBQFDwCGouABwFAUPAAYioIHAENR8ABgqFynARMTE2pqatIHH3wgl8ulAwcOyLZtNTQ0yLIsLV++XK2trcrJydGhQ4d06tQp5ebmqrGxUatWrZqN1wAAmIJjwb/77ruSpD/84Q/q6emZLPi6ujqtXbtWLS0tOnnypMrKynT+/HkdPXpUgUBAPp9Px44dS/kLAABMzbHgH3zwQW3YsEGS1N/fr5KSEp06dUrV1dWSJI/Ho/fee0/l5eWqqamRZVkqKyvTxMSEhoaGVFxcnNIXAACYmmPBS1Jubq7q6+v19ttv69e//rXeffddWZYlScrLy1MwGNTo6KiKioom/82N7dMVfDQald/vn+FLuDORSCRt507EXMiZyozucFgDgYDjuILBQfWHw7fdn+3zmCxkTI7ZyhhXwUtSe3u7nn32WX3nO99RNBqd3B4KhVRYWKj8/HyFQqGbthcUFEx7TLfbrcrKyjuIPXN+vz9t507EXMiZyoxX+/oULC11HHd3SYnuWrLktvuzfR6ThYzJMdOM8b45OF5F8+abb+rll1+WJM2fP1+WZWnlypXq6emRJHV3d6uqqkpr1qzR6dOnFYvF1N/fr1gsxvIMAKSR4yf4jRs3ateuXdq2bZuuX7+uxsZGLVu2TM3Nzero6FBFRYW8Xq9cLpeqqqpUW1urWCymlpaW2cgPALgNx4JfsGCBfvWrX92yvbOz85ZtPp9PPp8vOckAADPCjU4AYCgKHgAMRcEDgKEoeAAwFAUPAIai4AHAUBQ8ABiKggcAQ1HwAGAoCh4ADEXBA4ChKHgAMBQFDwCGouABwFAUPAAYioIHAENR8ABgqLi/dBvAzESGhxUdGbntfnc4rKt9fXIXFmrewoWzmAymouCBWRIdGdGHJ07cdv9AIKBgaamWer0UPJKCJRoAMBQFDwCGouABwFAUPAAYioIHAENR8ABgKAoeAAxFwQOAoSh4ADAUBQ8AhqLgAcBQFDwAGIqCBwBDUfAAYCgKHgAMRcEDgKEoeAAwFN/oBCPErl/X1b6+2+7n6/CQjSh4GGE8FFLg3Lnb7ufr8JCNWKIBAENN+wl+fHxcjY2N+vjjjzU2NqYnn3xS9913nxoaGmRZlpYvX67W1lbl5OTo0KFDOnXqlHJzc9XY2KhVq1bN1msAki4yPKzoyIjjOJZ8kMmmLfi33npLRUVFOnjwoIaHh/XNb35T999/v+rq6rR27Vq1tLTo5MmTKisr0/nz53X06FEFAgH5fD4dO3Zstl4DkHTRkRF9eOKE4ziWfJDJpi34hx56SF6vd/Jnl8ul3t5eVVdXS5I8Ho/ee+89lZeXq6amRpZlqaysTBMTExoaGlJxcXFq0wMJcvpj7A3Xr12bhTRAak1b8Hl5eZKk0dFRPfPMM6qrq1N7e7ssy5rcHwwGNTo6qqKiopv+XTAYdCz4aDQqv98/09dwRyKRSNrOnYi5kDOVGd3hsAYCAcdxRQ7jxsfHNRAIqOg//9H7cXwyv9/rjeu8BYOD6g+HHcdJzq/lRsZEjjnbsv33MVlmK6PjVTSBQEA//OEPtXXrVj388MM6ePDg5L5QKKTCwkLl5+crFArdtL2goMDx5G63W5WVlXcYfWb8fn/azp2IuZAzlRmv9vUpWFrqOG7+ggVaNM24gUBAi0pLHcfFe7wb7i4p0V1LljiOk5xfy42MiRxztmX772OyzDRjvG8O015FMzg4qB07dui5557Tpk2bJEkrVqxQT0+PJKm7u1tVVVVas2aNTp8+rVgspv7+fsViMZZnACDNpv0E/7vf/U4jIyN66aWX9NJLL0mSdu/erba2NnV0dKiiokJer1cul0tVVVWqra1VLBZTS0vLrIQHANzetAXf1NSkpqamW7Z3dnbess3n88nn8yUvGQBgRrjRCQAMRcEDgKEoeAAwFAUPAIai4AHAUBQ8ABiK58EjLeJ9WiPPhAHuHAWPtIj3aY2l69bNQhrATCzRAIChKHgAMBRLNMAMxPt8eYm/J2D2UfDADDh92fdn8fcEzDaWaADAUBQ8ABiKggcAQ1HwAGAoCh4ADMVVNFks3scFuAsLNW/hwllIBCCZKPgsFu/jApZ6vRQ8MAexRAMAhqLgAcBQLNEgaeJd05e4bR+YDRQ8kibeNX2J2/aB2cASDQAYioIHAENR8ABgKAoeAAxFwQOAoSh4ADAUBQ8AhqLgAcBQ3OgER05fLO0Oh3W1r4+7U4EMQ8HDkdMXSw8EAgqWlnJ3KpBhWKIBAENR8ABgKAoeAAxFwQOAoSh4ADAUBQ8Ahoqr4C9duqTt27dLkvr6+rRlyxZt3bpVra2tisVikqRDhw5p06ZN2rx5sy5fvpy6xACAuDgW/KuvvqqmpiZFo1FJ0oEDB1RXV6fXX39dtm3r5MmT6u3t1fnz53X06FF1dHRo7969KQ8OAJieY8EvXrxYL7744uTPvb29qq6uliR5PB6dOXNGFy5cUE1NjSzLUllZmSYmJjQ0NJS61AAAR44F7/V6lZv76Q2vtm3LsixJUl5enoLBoEZHR5Wfnz855sZ2AED6JPyogpycT98TQqGQCgsLlZ+fr1AodNP2goICx2NFo1H5/f5EIyRFJBJJ27kTkcqc7nBYA4GA47gih3Hj4+MaCAQcxyVyzGSPSzRjssclkrFgcFD94XBcx5xtc+H/GzJ+KuGCX7FihXp6erR27Vp1d3dr3bp1Wrx4sQ4ePKidO3dqYGBAsVhMxcXFjsdyu92qrKy8o+Az5ff703buRKQy59W+PgVLSx3HzV+wQIumGTcQCGhRaanjuESOmexxiWZM9rhEMt5dUqK7liyJ65izbS78f5MNGeN9c0i44Ovr69Xc3KyOjg5VVFTI6/XK5XKpqqpKtbW1isViamlpSTgwACC54ir4e++9V0eOHJEklZeXq7Oz85YxPp9PPp8vuekAAHeMG50AwFAUPAAYioIHAENR8ABgKAoeAAxFwQOAofjSbSDDxK5f19W+PsdxOS6XYhMTjuPchYWat3BhMqJhjqHggQwzHgopcO6c47jSdeviGrfU66XgsxRLNABgKAoeAAxFwQOAoSh4ADAUBQ8AhqLgAcBQXCYJQJIUGR5WdGRk2jHucFiR4WEuu5wjKHgAkqToyIg+PHFi2jEDgYDufvxxCn6OYIkGAAxFwQOAoSh4ADAUBQ8AhqLgAcBQFDwAGIrLJAHDxft8+evXrs1CGswmCh4wXCLPl4dZWKIBAENR8ABgKJZoDBTPM0Uk1lwB01HwBornmSISa66A6Sj4OYRP5gASQcHPIXwyB5AI/sgKAIai4AHAUBQ8ABiKNfgMMN0fT93h8ORt5vzxFEAiKPgUSuSql4+6u6fcNxAIKFhaKok/ngJIDAWfQlz1AiCdKHgACYn36ZTuwkK+nDvNKHgACYn36ZRLvV4KPs24igYADMUneAApEe9SjsRyTqokteBjsZj27Nmjv/3tb/riF7+otrY2LVmyJJmnADBHxLuUI8W/nBPPlWnucFiR4WHeMJTkgn/nnXc0NjamP/7xj7p48aKef/55/fa3v03mKdIu3ksfJa5bB+KVyNcK3u6S4hsGAgHd/fjjFLySXPAXLlzQAw88IElavXq1rly5kszD3yTeos1xuRSbmLhl+2dvIJpu3OfF8wt2A5c/AvFJ19cKxtsj8S4hxXu8+XGlmznLtm07WQfbvXu3Nm7cqPXr10uSNmzYoHfeeUe5uVO/j1y8eFFutztZpweArBCNRrV69WrHcUn9BJ+fn69QKDT5cywWu225S4orIADgziT1Msk1a9ao+/+XLy5evKgvf/nLyTw8ACABSV2iuXEVzd///nfZtq39+/dr2bJlyTo8ACABSS14AEDm4E5WADAUBQ8AhsqqRxVcunRJL7zwgg4fPqze3l498cQTWrp0qSRpy5Yt+trXvpa2bOPj42psbNTHH3+ssbExPfnkk7rvvvvU0NAgy7K0fPlytba2Kicnfe/JU2VctGhRRs2jJE1MTKipqUkffPCBXC6XDhw4INu2M2oup8oYDAYzbi4l6ZNPPtG3vvUt/f73v1dubm5GzeNUGSORSMbN4ze+8Q0VFBRIku69917V1tbqF7/4hVwul2pqavT000+n5sR2lnjllVfsr3/96/a3v/1t27Zt+8iRI/Zrr72W5lSfeuONN+y2tjbbtm17aGjIXr9+vf2DH/zAPnfunG3btt3c3Gz/+c9/TmfEKTNm2jzatm2//fbbdkNDg23btn3u3Dn7iSeeyLi5nCpjJs7l2NiY/dRTT9kbN260//GPf2TcPNr2rRkzbR4jkYj96KOP3rTtkUcesfv6+uxYLGZ/97vfta9cuZKSc6f/rXeWLF68WC+++OLkz1euXNGpU6e0bds2NTY2anR0NI3ppIceekg/+tGPJn92uVzq7e1VdXW1JMnj8ejMmTPpiidp6oyZNo+S9OCDD2rfvn2SpP7+fpWUlGTcXE6VMRPnsr29XZs3b9Y999wjSRk3j9KtGTNtHt9//31du3ZNO3bs0GOPPaa//OUvGhsb0+LFi2VZlmpqanT27NmUnDtrCt7r9d5009WqVav0s5/9TF1dXfrSl76k3/zmN2lMJ+Xl5Sk/P1+jo6N65plnVFdXJ9u2ZVnW5P5gMJhxGTNtHm/Izc1VfX299u3bJ6/Xm3FzKd2aMdPm8vjx4youLp58/IikjJvHqTJm2jzOmzdPO3fu1Guvvaa9e/dq165dmj//04cVpHIes6bgP++rX/2qVq5cOfnff/3rX9OcSAoEAnrsscf06KOP6uGHH75pbTMUCqmwsDCN6f7P5zNm4jze0N7erhMnTqi5uVnRaHRye6bMpXRzxpqamoyay2PHjunMmTPavn27/H6/6uvrNTQ0NLk/E+Zxqowejyej5rG8vFyPPPKILMtSeXm5CgoK9N///ndyfyrnMWsLfufOnbp8+bIk6ezZs/rKV76S1jyDg4PasWOHnnvuOW3atEmStGLFCvX09EiSuru7VVVVlc6IU2bMtHmUpDfffFMvv/yyJGn+/PmyLEsrV67MqLmcKuPTTz+dUXPZ1dWlzs5OHT58WJWVlWpvb5fH48moeZwq41NPPZVR8/jGG2/o+eeflyT9+9//1rVr17RgwQL961//km3bOn36dMrmMatudProo4/0k5/8REeOHFFvb6/27dunL3zhCyopKdG+ffuUn5+ftmxtbW3605/+pIqKisltu3fvVltbm8bHx1VRUaG2tja5XK6MylhXV6eDBw9mzDxKUjgc1q5duzQ4OKjr16/re9/7npYtW6bm5uaMmcupMpaWlmbU7+Rnbd++XXv27FFOTk5GzeNn3cgYiUQyah7Hxsa0a9cu9ff3y7IsPfvss8rJydH+/fs1MTGhmpoa/fjHP07JubOq4AEgm2TtEg0AmI6CBwBDUfAAYCgKHgAMRcEDgKEoeOA2Ll26pO3bt6c7BnDHsuppkkC8Xn31Vb311ls33VIOzDV8gkfW6+rq0k9/+lNJUn19vbq6um55OB0wF1HwyHrbtm3TtWvX1NDQoPHxcW3btu2Wh9MBcxG/wYCk73//+6qtrdXx48fTHQVIGj7BI+uNjY1p//79+vnPf649e/ZobGws3ZGApKDgkfVeeOEFbdiwQbW1tfJ4PPrlL3+Z7khAUvCwMQAwFJ/gAcBQFDwAGIqCBwBDUfAAYCgKHgAMRcEDgKEoeAAwFAUPAIb6H8KT00fCa55WAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#histogram of x1 , possibly age\n",
    "sns.distplot(train['x1'].dropna(),kde=False,color='darkred',bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting categorical to dummy and making dataset ready for analysis\n",
    "#train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x5 = pd.get_dummies(train['x5'],drop_first=True)\n",
    "x13 = pd.get_dummies(train['x13'],drop_first=True)\n",
    "x65 = pd.get_dummies(train['x65'],drop_first=True)\n",
    "x64 = pd.get_dummies(train['x66'],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train,x5,x13,x64,x65],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['x5','x13','x64','x65','Row'],axis=1,inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>x11</th>\n",
       "      <th>...</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>beta</th>\n",
       "      <th>chi</th>\n",
       "      <th>1</th>\n",
       "      <th>NST</th>\n",
       "      <th>PT</th>\n",
       "      <th>ST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>53.3</td>\n",
       "      <td>54.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>113.6</td>\n",
       "      <td>199.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>182.4</td>\n",
       "      <td>48.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>25.1</td>\n",
       "      <td>27.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>10.1</td>\n",
       "      <td>145.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      x1  x2  x3  x4  x6  x7  x8  x9    x10    x11 ...  B  C  D  E  beta  chi  \\\n",
       "2495  34   1   0   1   5   8   8  34   53.3   54.8 ...  0  1  0  0     0    0   \n",
       "2496  29   0   1   1   1   3   1  32  113.6  199.3 ...  0  0  0  1     0    1   \n",
       "2497  30   0   1   1  17  12  10  21  182.4   48.5 ...  0  0  0  0     1    0   \n",
       "2498  38   1   0   1   1  13   6  30   25.1   27.9 ...  0  1  0  0     0    0   \n",
       "2499  26   1   1   1  14   2   3  30   10.1  145.5 ...  0  0  0  1     0    1   \n",
       "\n",
       "      1  NST  PT  ST  \n",
       "2495  1    0   1   0  \n",
       "2496  1    0   0   1  \n",
       "2497  1    0   0   0  \n",
       "2498  1    0   1   0  \n",
       "2499  1    0   0   1  \n",
       "\n",
       "[5 rows x 73 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.drop(['Row'],axis = 1 ,inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making dataset ready\n",
    "#we are gonna treat our test data as the whole data\n",
    "\n",
    "X = train.drop('y',axis = 1) #predictiors\n",
    "Y = train['y']  #column that we want to predict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting train data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.30, \n",
    "                                                    random_state=101)\n",
    "#X_test.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>x11</th>\n",
       "      <th>...</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>beta</th>\n",
       "      <th>chi</th>\n",
       "      <th>1</th>\n",
       "      <th>NST</th>\n",
       "      <th>PT</th>\n",
       "      <th>ST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>33</td>\n",
       "      <td>117.2</td>\n",
       "      <td>82.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>29</td>\n",
       "      <td>43.1</td>\n",
       "      <td>100.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>38</td>\n",
       "      <td>60.2</td>\n",
       "      <td>133.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1685</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>60.1</td>\n",
       "      <td>93.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>118.9</td>\n",
       "      <td>141.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      x1  x2  x3  x4  x6  x7  x8  x9    x10    x11 ...  B  C  D  E  beta  chi  \\\n",
       "537   26   1   0   1  14  13   9  33  117.2   82.2 ...  0  0  1  0     0    0   \n",
       "379   37   0   1   1   3   2  18  29   43.1  100.7 ...  0  0  0  0     1    0   \n",
       "753   28   1   1   0   9   6  11  38   60.2  133.0 ...  0  0  0  0     1    0   \n",
       "1685  22   0   0   1   2   4   4  28   60.1   93.4 ...  0  0  0  0     1    0   \n",
       "1230  33   1   1   1  12  14   1  35  118.9  141.6 ...  0  1  0  0     1    0   \n",
       "\n",
       "      1  NST  PT  ST  \n",
       "537   1    1   0   0  \n",
       "379   1    0   0   0  \n",
       "753   0    0   0   0  \n",
       "1685  1    0   0   0  \n",
       "1230  1    0   1   0  \n",
       "\n",
       "[5 rows x 72 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head() #inspecting the training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "537    -1\n",
       "379    -1\n",
       "753    -1\n",
       "1685    1\n",
       "1230   -1\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>x11</th>\n",
       "      <th>...</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>beta</th>\n",
       "      <th>chi</th>\n",
       "      <th>1</th>\n",
       "      <th>NST</th>\n",
       "      <th>PT</th>\n",
       "      <th>ST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2415</th>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>40</td>\n",
       "      <td>60.7</td>\n",
       "      <td>75.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>34</td>\n",
       "      <td>26.9</td>\n",
       "      <td>121.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>34</td>\n",
       "      <td>141.8</td>\n",
       "      <td>100.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166</th>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>5.2</td>\n",
       "      <td>66.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>72.7</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      x1  x2  x3  x4  x6  x7  x8  x9    x10    x11 ...  B  C  D  E  beta  chi  \\\n",
       "2415  29   0   1   1  10   9  15  40   60.7   75.8 ...  0  0  0  1     0    1   \n",
       "218   28   0   0   0   2   7  14  34   26.9  121.1 ...  0  0  0  0     1    0   \n",
       "469   30   0   0   1  15   2  17  34  141.8  100.7 ...  0  0  0  0     1    0   \n",
       "1166  32   0   0   1   3  18   6  30    5.2   66.4 ...  0  0  0  0     1    0   \n",
       "254   23   1   0   1  11   8   5  26   72.7   12.0 ...  1  0  0  0     0    1   \n",
       "\n",
       "      1  NST  PT  ST  \n",
       "2415  1    0   0   1  \n",
       "218   1    0   0   0  \n",
       "469   1    0   0   0  \n",
       "1166  0    0   0   0  \n",
       "254   1    1   0   0  \n",
       "\n",
       "[5 rows x 72 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2415   -1\n",
       "218     1\n",
       "469    -1\n",
       "1166    1\n",
       "254    -1\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count of 1 428\n",
      "count of -1 1322\n"
     ]
    }
   ],
   "source": [
    "#We can see that our model is getting trained in the training set with 1322 instances with y = 1 is and 428 instances with y = -1\n",
    "count1 = 0\n",
    "count01 = 0\n",
    "for i in y_train:\n",
    "    if i==1:\n",
    "        count1=count1+1\n",
    "    if i==-1:\n",
    "        count01 = count01+1\n",
    "print('count of 1',count1)\n",
    "print('count of -1',count01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    1322\n",
       " 1     428\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count of 1 181\n",
      "count of -1 569\n"
     ]
    }
   ],
   "source": [
    "#We can see that our model is getting testes in the testing set with 569 instances with y = 1 is and 181 instances with y = -1\n",
    "count1 = 0\n",
    "count01 = 0\n",
    "for i in y_test:\n",
    "    if i==1:\n",
    "        count1=count1+1\n",
    "    if i==-1:\n",
    "        count01 = count01+1\n",
    "print('count of 1',count1)\n",
    "print('count of -1',count01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    569\n",
       " 1    181\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying logistics in unbalanced data\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "logmodel = LogisticRegression()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jay Bhanushali\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logmodel.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = logmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.87      0.92      0.90       569\n",
      "           1       0.70      0.59      0.64       181\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       750\n",
      "   macro avg       0.79      0.75      0.77       750\n",
      "weighted avg       0.83      0.84      0.83       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[524  45]\n",
      " [ 75 106]]\n",
      "balance_error_rate 0.246725378438474\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_array = confusion_matrix(y_test,predictions)\n",
    "print(confusion_array)\n",
    "balance_error_rate = (confusion_array[0][1]/sum(confusion_array[0])) + ((confusion_array[1][0])/sum(confusion_array[1]))\n",
    "\n",
    "print('balance_error_rate', balance_error_rate/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.85      0.85      0.85       569\n",
      "           1       0.53      0.54      0.54       181\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       750\n",
      "   macro avg       0.69      0.69      0.69       750\n",
      "weighted avg       0.78      0.77      0.77       750\n",
      "\n",
      "[[482  87]\n",
      " [ 83  98]]\n",
      "balance_error_rate 0.30573168008233886\n"
     ]
    }
   ],
   "source": [
    "#decision trees on y_test on unbalanced data\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree = DecisionTreeClassifier()\n",
    "dtree.fit(X_train,y_train)\n",
    "predictions_tree = dtree.predict(X_test)\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(y_test,predictions_tree))\n",
    "print(confusion_matrix(y_test,predictions_tree))\n",
    "confusion_array2 = confusion_matrix(y_test,predictions_tree)\n",
    "balance_error_rate2 = (confusion_array2[0][1]/sum(confusion_array2[0])) + ((confusion_array2[1][0])/sum(confusion_array2[1]))\n",
    "\n",
    "print('balance_error_rate',balance_error_rate2/2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[533  36]\n",
      " [ 84  97]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.86      0.94      0.90       569\n",
      "           1       0.73      0.54      0.62       181\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       750\n",
      "   macro avg       0.80      0.74      0.76       750\n",
      "weighted avg       0.83      0.84      0.83       750\n",
      "\n",
      "balance_error_rate 0.2636786452922157\n"
     ]
    }
   ],
   "source": [
    "#applying random forest on unbalanced data\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=100)\n",
    "rfc.fit(X_train, y_train)\n",
    "rfc_pred = rfc.predict(X_test)\n",
    "print(confusion_matrix(y_test,rfc_pred))\n",
    "print(classification_report(y_test,rfc_pred))\n",
    "confusion_array3 = confusion_matrix(y_test,rfc_pred)\n",
    "\n",
    "balance_error_rate3 = (confusion_array3[0][1]/sum(confusion_array3[0])) + ((confusion_array3[1][0])/sum(confusion_array3[1]))\n",
    "\n",
    "print('balance_error_rate',balance_error_rate3/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RESAMPLING\n",
    "#UPSAMPLING\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate majority and minority classes\n",
    "train_majority = train[train.y == -1]\n",
    "train_minority = train[train.y == 1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsample minority class\n",
    "# Upsample minority class\n",
    "train_minority_upsampled = resample(train_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=1891,    # to match majority class train['y'].value_counts() - 1 comes out as 1891\n",
    "                                 random_state=123) # reproducible results\n",
    "# Combine majority class with upsampled minority class\n",
    "train_upsampled = pd.concat([train_majority, train_minority_upsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    1891\n",
       "-1    1891\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_upsampled['y'].value_counts()  #in this dataframe the values of y = -1 and y = +1 are same\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jay Bhanushali\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.84      0.80      0.82      1891\n",
      "           1       0.81      0.85      0.83      1891\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      3782\n",
      "   macro avg       0.83      0.83      0.83      3782\n",
      "weighted avg       0.83      0.83      0.83      3782\n",
      "\n",
      "[[1511  380]\n",
      " [ 281 1610]]\n",
      "0.34955050237969326\n"
     ]
    }
   ],
   "source": [
    "##NOT IMPORTANT\n",
    "#Upsampled data sets \n",
    "y_train_upsampled = train_upsampled.y\n",
    "X_train_upsampled = train_upsampled.drop('y', axis=1)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "# Train model Logistic regression on upsampled data\n",
    "clf_1 = LogisticRegression().fit(X_train_upsampled, y_train_upsampled )\n",
    "\n",
    "# Predict on training set\n",
    "pred_y_1 = clf_1.predict(X_train_upsampled)\n",
    "\n",
    "#prediction report\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(classification_report(y_train_upsampled,pred_y_1))\n",
    "print(confusion_matrix(y_train_upsampled,pred_y_1))\n",
    "confusion_array4 = confusion_matrix(y_train_upsampled,pred_y_1)\n",
    "\n",
    "balance_error_rate4 = (confusion_array4[0][1]/sum(confusion_array4[0])) + ((confusion_array4[1][0])/sum(confusion_array4[1]))\n",
    "\n",
    "print(balance_error_rate4)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.94      0.78      0.85       569\n",
      "           1       0.54      0.85      0.66       181\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       750\n",
      "   macro avg       0.74      0.81      0.76       750\n",
      "weighted avg       0.84      0.79      0.80       750\n",
      "\n",
      "[[441 128]\n",
      " [ 28 153]]\n",
      "balance_error_rate 0.18982609793278893\n"
     ]
    }
   ],
   "source": [
    "#Applying this loGISTIC regression model trained on upsampled data to predict on the original test data\n",
    "pred_y_original_testing_data = clf_1.predict(X_test)\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(classification_report(y_test,pred_y_original_testing_data))\n",
    "print(confusion_matrix(y_test,pred_y_original_testing_data))\n",
    "confusion_array5 = confusion_matrix(y_test,pred_y_original_testing_data)\n",
    "\n",
    "balance_error_rate5 = (confusion_array5[0][1]/sum(confusion_array5[0])) + ((confusion_array5[1][0])/sum(confusion_array5[1]))\n",
    "\n",
    "print('balance_error_rate',balance_error_rate5/2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      1.00      1.00      1891\n",
      "           1       1.00      1.00      1.00      1891\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      3782\n",
      "   macro avg       1.00      1.00      1.00      3782\n",
      "weighted avg       1.00      1.00      1.00      3782\n",
      "\n",
      "[[1891    0]\n",
      " [   0 1891]]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Training decision tree on upscaled data\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree2 = DecisionTreeClassifier()\n",
    "dtree_fitted = dtree2.fit(X_train_upsampled,y_train_upsampled)\n",
    "predictions_tree2 = dtree_fitted.predict(X_train_upsampled)\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(y_train_upsampled,predictions_tree2))\n",
    "print(confusion_matrix(y_train_upsampled,predictions_tree2))\n",
    "confusion_array6 = confusion_matrix(y_train_upsampled,predictions_tree2)\n",
    "balance_error_rate6 = (confusion_array6[0][1]/sum(confusion_array6[0])) + ((confusion_array6[1][0])/sum(confusion_array6[1]))\n",
    "\n",
    "print(balance_error_rate6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.99      1.00      1.00      1891\n",
      "           1       1.00      0.98      0.99       609\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      2500\n",
      "   macro avg       1.00      0.99      0.99      2500\n",
      "weighted avg       0.99      0.99      0.99      2500\n",
      "\n",
      "[[1891    0]\n",
      " [  14  595]]\n",
      "0.022988505747126436\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Applying this Decision tree model trained on upsampled data to predict on the original test data\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "pred_y_original_testing_data2 = dtree_fitted.predict(X)\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(classification_report(Y,pred_y_original_testing_data2))\n",
    "print(confusion_matrix(Y,pred_y_original_testing_data2))\n",
    "confusion_array7 = confusion_matrix(Y,pred_y_original_testing_data2)\n",
    "\n",
    "balance_error_rate7 = (confusion_array7[0][1]/sum(confusion_array7[0])) + ((confusion_array7[1][0])/sum(confusion_array7[1]))\n",
    "\n",
    "print(balance_error_rate7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1891    0]\n",
      " [   0 1891]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      1.00      1.00      1891\n",
      "           1       1.00      1.00      1.00      1891\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      3782\n",
      "   macro avg       1.00      1.00      1.00      3782\n",
      "weighted avg       1.00      1.00      1.00      3782\n",
      "\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Training random on upscaled data\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc2 = RandomForestClassifier(n_estimators=100)\n",
    "rfc_fitted_upsampled = rfc2.fit(X_train_upsampled, y_train_upsampled )\n",
    "rfc_pred2 = rfc_fitted_upsampled.predict(X_train_upsampled)\n",
    "print(confusion_matrix(y_train_upsampled,rfc_pred2))\n",
    "print(classification_report(y_train_upsampled,rfc_pred2))\n",
    "confusion_array8 = confusion_matrix(y_train_upsampled,rfc_pred2)\n",
    "\n",
    "balance_error_rate8 = (confusion_array8[0][1]/sum(confusion_array8[0])) + ((confusion_array8[1][0])/sum(confusion_array8[1]))\n",
    "\n",
    "print(balance_error_rate8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.99      1.00      1.00      1891\n",
      "           1       1.00      0.98      0.99       609\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      2500\n",
      "   macro avg       1.00      0.99      0.99      2500\n",
      "weighted avg       1.00      1.00      1.00      2500\n",
      "\n",
      "[[1891    0]\n",
      " [  12  597]]\n",
      "0.019704433497536946\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Applying this RANDOM FOREST model trained on upsampled data to predict on the original test data\n",
    "pred_y_original_testing_data2 = rfc_fitted_upsampled.predict(X)\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(classification_report(Y,pred_y_original_testing_data2))\n",
    "print(confusion_matrix(Y,pred_y_original_testing_data2))\n",
    "confusion_array7 = confusion_matrix(Y,pred_y_original_testing_data2)\n",
    "\n",
    "balance_error_rate7 = (confusion_array7[0][1]/sum(confusion_array7[0])) + ((confusion_array7[1][0])/sum(confusion_array7[1]))\n",
    "\n",
    "print(balance_error_rate7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    1322\n",
       " 1     428\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#RESAMPLING\n",
    "#UPSAMPLING\n",
    "#Splitting training data into 2 portions - training and testing and then , upsampling on training data and then testing on testing data\n",
    "#splitted_train_data = pd.concat([X_train,y_train])\n",
    "#splitted_train_data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "splitted_train_data, splitted_test_data = train_test_split(train2, test_size=0.2)\n",
    "from sklearn.utils import resample\n",
    "train_majority2 = splitted_train_data[splitted_train_data.y == -1]\n",
    "train_minority2 = splitted_train_data[splitted_train_data.y == 1]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsample minority class\n",
    "train_minority_upsampled2 = resample(train_minority2, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=1523,    # to match majority class splitted_train_data['y'].value_counts() - 1 comes out as 1891\n",
    "                                 random_state=123) # reproducible results\n",
    "\n",
    "# Combine majority class with upsampled minority class\n",
    "train_upsampled2 = pd.concat([train_majority2, train_minority2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_upsampled23 = train_upsampled2.y\n",
    "X_train_upsampled23 = train_upsampled2.drop('y', axis=1)\n",
    "y_test_upsampled23 = splitted_test_data.y\n",
    "X_test_upsampled23= splitted_test_data.drop('y', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>x11</th>\n",
       "      <th>...</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>beta</th>\n",
       "      <th>chi</th>\n",
       "      <th>1</th>\n",
       "      <th>NST</th>\n",
       "      <th>PT</th>\n",
       "      <th>ST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1720</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>118.4</td>\n",
       "      <td>106.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1626</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>123.3</td>\n",
       "      <td>124.6</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>24.4</td>\n",
       "      <td>93.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>35</td>\n",
       "      <td>26.8</td>\n",
       "      <td>192.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>26</td>\n",
       "      <td>35.2</td>\n",
       "      <td>186.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      x1  x2  x3  x4  x6  x7  x8  x9    x10    x11 ...  B  C  D  E  beta  chi  \\\n",
       "1720  31   1   1   1  10  13   2  35  118.4  106.3 ...  0  0  0  0     1    0   \n",
       "1626  27   0   0   1   0  17   5  28  123.3  124.6 ...  1  0  0  0     0    1   \n",
       "237   31   0   0   1  15  16   8  30   24.4   93.0 ...  0  0  0  1     1    0   \n",
       "1962  27   1   0   1   4  16  16  35   26.8  192.8 ...  0  1  0  0     1    0   \n",
       "1185  31   1   1   1   9  13  15  26   35.2  186.2 ...  0  0  0  0     1    0   \n",
       "\n",
       "      1  NST  PT  ST  \n",
       "1720  1    0   0   0  \n",
       "1626  1    0   0   0  \n",
       "237   1    1   0   0  \n",
       "1962  1    1   0   0  \n",
       "1185  1    0   0   0  \n",
       "\n",
       "[5 rows x 72 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_upsampled23.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[346  22]\n",
      " [ 52  80]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.87      0.94      0.90       368\n",
      "           1       0.78      0.61      0.68       132\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       500\n",
      "   macro avg       0.83      0.77      0.79       500\n",
      "weighted avg       0.85      0.85      0.85       500\n",
      "\n",
      "balance error rate 0.22686100131752304\n"
     ]
    }
   ],
   "source": [
    "#TRAINING RANDOM FOREST ON THIS SAMPLES AND TESTING ON TETSING DATA(AFTER UPSAMPLING)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc5 = RandomForestClassifier(n_estimators=100)\n",
    "rfc_SAMPLED_upsampled= rfc5.fit(X_train_upsampled23, y_train_upsampled23)\n",
    "rfc_pred23 = rfc_SAMPLED_upsampled.predict(X_test_upsampled23)\n",
    "print(confusion_matrix(y_test_upsampled23 ,rfc_pred23))\n",
    "print(classification_report(y_test_upsampled23 ,rfc_pred23))\n",
    "confusion_array10 = confusion_matrix(y_test_upsampled23 ,rfc_pred23)\n",
    "\n",
    "balance_error_rate10 = (confusion_array10[0][1]/sum(confusion_array10[0])) + ((confusion_array10[1][0])/sum(confusion_array10[1]))\n",
    "\n",
    "print('balance error rate',balance_error_rate10/2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.88      0.92      0.90       368\n",
      "           1       0.74      0.65      0.69       132\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       500\n",
      "   macro avg       0.81      0.78      0.80       500\n",
      "weighted avg       0.84      0.85      0.84       500\n",
      "\n",
      "[[338  30]\n",
      " [ 46  86]]\n",
      "balance error rate 0.21500329380764166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jay Bhanushali\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#TRAINING Logistics ON THIS SAMPLES AND TESTING ON TETSING DATA(AFTER UPSAMPLING)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logmodel_train2_train_upsampled = LogisticRegression()\n",
    "logmodel_train2_train_upsampled.fit(X_train_upsampled23,y_train_upsampled23)\n",
    "logmodel_train2_upsampled_predictions_logistics = logmodel_train2_train_upsampled.predict(X_test_upsampled23)\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(classification_report(y_test_upsampled23,logmodel_train2_upsampled_predictions_logistics))\n",
    "print(confusion_matrix(y_test_upsampled23,logmodel_train2_upsampled_predictions_logistics))\n",
    "confusion_array25 = confusion_matrix(y_test_upsampled23,logmodel_train2_upsampled_predictions_logistics)\n",
    "\n",
    "balance_error_rate25 = (confusion_array25[0][1]/sum(confusion_array25[0])) + ((confusion_array25[1][0])/sum(confusion_array25[1]))\n",
    "\n",
    "print('balance error rate',balance_error_rate25/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1869   22]\n",
      " [  52  557]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.97      0.99      0.98      1891\n",
      "           1       0.96      0.91      0.94       609\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      2500\n",
      "   macro avg       0.97      0.95      0.96      2500\n",
      "weighted avg       0.97      0.97      0.97      2500\n",
      "\n",
      "0.09701993454432413\n"
     ]
    }
   ],
   "source": [
    "##Not important\n",
    "rfc_pred24 = rfc_SAMPLED_upsampled.predict(X)\n",
    "print(confusion_matrix(Y ,rfc_pred24))\n",
    "print(classification_report(Y ,rfc_pred24))\n",
    "confusion_array11 = confusion_matrix(Y ,rfc_pred24)\n",
    "\n",
    "balance_error_rate11 = (confusion_array11[0][1]/sum(confusion_array11[0])) + ((confusion_array11[1][0])/sum(confusion_array11[1]))\n",
    "\n",
    "print(balance_error_rate11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#APPLYING SMOTE\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "smt = SMOTE()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_smote, y_train_smote = smt.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    1322\n",
       "-1    1322\n",
       "dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(pd.Series(y_train_smote)) #converting numpy array into pd and using value.counts\n",
    "#we have equal +1s and -1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying logistics regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.93      0.75      0.83       569\n",
      "           1       0.51      0.82      0.63       181\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       750\n",
      "   macro avg       0.72      0.78      0.73       750\n",
      "weighted avg       0.83      0.77      0.78       750\n",
      "\n",
      "[[426 143]\n",
      " [ 33 148]]\n",
      "balance error rate 0.21681927196108325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jay Bhanushali\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#applying logistics in to data by SMOTE (trained on smote trained data, tested on test data)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logmodel_smote = LogisticRegression()\n",
    "logmodel_smote.fit(X_train_smote,y_train_smote)\n",
    "predictions_smote_logistics = logmodel_smote.predict(X_test)\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(classification_report(y_test,predictions_smote_logistics))\n",
    "print(confusion_matrix(y_test,predictions_smote_logistics))\n",
    "confusion_array13 = confusion_matrix(y_test,predictions_smote_logistics)\n",
    "\n",
    "balance_error_rate13 = (confusion_array13[0][1]/sum(confusion_array13[0])) + ((confusion_array13[1][0])/sum(confusion_array13[1]))\n",
    "\n",
    "print('balance error rate',balance_error_rate13/2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jay Bhanushali\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.93      0.76      0.83       569\n",
      "           1       0.51      0.81      0.63       181\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       750\n",
      "   macro avg       0.72      0.78      0.73       750\n",
      "weighted avg       0.83      0.77      0.78       750\n",
      "\n",
      "[[430 139]\n",
      " [ 34 147]]\n",
      "balance error rate 0.21606676441173328\n"
     ]
    }
   ],
   "source": [
    "#applying logistics in to data by SMOTE (trained on smote trained data, tested on test data)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logmodel_smote = LogisticRegression(C=100)\n",
    "logmodel_smote.fit(X_train_smote,y_train_smote)\n",
    "predictions_smote_logistics = logmodel_smote.predict(X_test)\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(classification_report(y_test,predictions_smote_logistics))\n",
    "print(confusion_matrix(y_test,predictions_smote_logistics))\n",
    "confusion_array13 = confusion_matrix(y_test,predictions_smote_logistics)\n",
    "\n",
    "balance_error_rate13 = (confusion_array13[0][1]/sum(confusion_array13[0])) + ((confusion_array13[1][0])/sum(confusion_array13[1]))\n",
    "\n",
    "print('balance error rate',balance_error_rate13/2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.92      0.76      0.83       569\n",
      "           1       0.51      0.81      0.63       181\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       750\n",
      "   macro avg       0.72      0.78      0.73       750\n",
      "weighted avg       0.83      0.77      0.78       750\n",
      "\n",
      "[[430 139]\n",
      " [ 35 146]]\n",
      "balance error rate 0.21882919535095982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jay Bhanushali\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#applying logistics in to data by SMOTE (trained on smote trained data, tested on test data)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logmodel_smote = LogisticRegression(C=100, penalty = 'l1')\n",
    "logmodel_smote.fit(X_train_smote,y_train_smote)\n",
    "predictions_smote_logistics = logmodel_smote.predict(X_test)\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(classification_report(y_test,predictions_smote_logistics))\n",
    "print(confusion_matrix(y_test,predictions_smote_logistics))\n",
    "confusion_array13 = confusion_matrix(y_test,predictions_smote_logistics)\n",
    "\n",
    "balance_error_rate13 = (confusion_array13[0][1]/sum(confusion_array13[0])) + ((confusion_array13[1][0])/sum(confusion_array13[1]))\n",
    "\n",
    "print('balance error rate',balance_error_rate13/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jay Bhanushali\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Jay Bhanushali\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Jay Bhanushali\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Jay Bhanushali\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Jay Bhanushali\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Jay Bhanushali\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Jay Bhanushali\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Jay Bhanushali\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Jay Bhanushali\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Jay Bhanushali\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Jay Bhanushali\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Jay Bhanushali\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Jay Bhanushali\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Jay Bhanushali\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Jay Bhanushali\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Jay Bhanushali\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Jay Bhanushali\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Jay Bhanushali\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Jay Bhanushali\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Jay Bhanushali\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Jay Bhanushali\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Jay Bhanushali\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Jay Bhanushali\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Jay Bhanushali\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Jay Bhanushali\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Jay Bhanushali\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Jay Bhanushali\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Jay Bhanushali\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Jay Bhanushali\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Jay Bhanushali\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Jay Bhanushali\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Jay Bhanushali\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Jay Bhanushali\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Jay Bhanushali\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Jay Bhanushali\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Jay Bhanushali\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Jay Bhanushali\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Jay Bhanushali\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Jay Bhanushali\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jay Bhanushali\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Jay Bhanushali\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Jay Bhanushali\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Jay Bhanushali\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Jay Bhanushali\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Jay Bhanushali\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Jay Bhanushali\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Jay Bhanushali\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Jay Bhanushali\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Jay Bhanushali\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Jay Bhanushali\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters {'C': 100, 'penalty': 'l1'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jay Bhanushali\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Trying grid search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_gridsearch = LogisticRegression()\n",
    "penalty = ['l1', 'l2']\n",
    "C = [0.0001, 0.001, 0.01, 1, 100]\n",
    "hyperparameters = dict(C=C, penalty=penalty)\n",
    "best_clf = GridSearchCV(logistic_gridsearch, hyperparameters, cv =5 , verbose=0)\n",
    "best_model = best_clf.fit(X_train_smote,y_train_smote)\n",
    "print('Best Parameters',best_clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[503  66]\n",
      " [ 65 116]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.89      0.88      0.88       569\n",
      "           1       0.64      0.64      0.64       181\n",
      "\n",
      "   micro avg       0.83      0.83      0.83       750\n",
      "   macro avg       0.76      0.76      0.76       750\n",
      "weighted avg       0.83      0.83      0.83       750\n",
      "\n",
      "balance error rate 0.2375544961112352\n"
     ]
    }
   ],
   "source": [
    "#applying Random forrest in to data by SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc_smote = RandomForestClassifier(n_estimators=100)\n",
    "rfc_smote.fit(X_train_smote,y_train_smote)\n",
    "rfc_pred_smote  = rfc_smote.predict(X_test)\n",
    "print(confusion_matrix(y_test,rfc_pred_smote))\n",
    "print(classification_report(y_test,rfc_pred_smote))\n",
    "confusion_array14 = confusion_matrix(y_test,rfc_pred_smote)\n",
    "\n",
    "balance_error_rate14 = (confusion_array14[0][1]/sum(confusion_array14[0])) + ((confusion_array14[1][0])/sum(confusion_array14[1]))\n",
    "\n",
    "print('balance error rate', balance_error_rate14/2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 100,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'max_iter': 100,\n",
       " 'multi_class': 'warn',\n",
       " 'n_jobs': None,\n",
       " 'penalty': 'l1',\n",
       " 'random_state': None,\n",
       " 'solver': 'warn',\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logmodel_smote.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv': 5,\n",
       " 'error_score': 'raise-deprecating',\n",
       " 'estimator__C': 1.0,\n",
       " 'estimator__class_weight': None,\n",
       " 'estimator__dual': False,\n",
       " 'estimator__fit_intercept': True,\n",
       " 'estimator__intercept_scaling': 1,\n",
       " 'estimator__max_iter': 100,\n",
       " 'estimator__multi_class': 'warn',\n",
       " 'estimator__n_jobs': None,\n",
       " 'estimator__penalty': 'l2',\n",
       " 'estimator__random_state': None,\n",
       " 'estimator__solver': 'warn',\n",
       " 'estimator__tol': 0.0001,\n",
       " 'estimator__verbose': 0,\n",
       " 'estimator__warm_start': False,\n",
       " 'estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       " 'fit_params': None,\n",
       " 'iid': 'warn',\n",
       " 'n_jobs': None,\n",
       " 'param_grid': {'C': [0.0001, 0.001, 0.01, 1, 100], 'penalty': ['l1', 'l2']},\n",
       " 'pre_dispatch': '2*n_jobs',\n",
       " 'refit': True,\n",
       " 'return_train_score': 'warn',\n",
       " 'scoring': None,\n",
       " 'verbose': 0}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "best_clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying svm\n",
    "from sklearn.svm import SVC\n",
    "model_svc_smote = SVC()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jay Bhanushali\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[569   0]\n",
      " [181   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.76      1.00      0.86       569\n",
      "           1       0.00      0.00      0.00       181\n",
      "\n",
      "   micro avg       0.76      0.76      0.76       750\n",
      "   macro avg       0.38      0.50      0.43       750\n",
      "weighted avg       0.58      0.76      0.65       750\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jay Bhanushali\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Jay Bhanushali\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Jay Bhanushali\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "model_svc_smote.fit(X_train_smote,y_train_smote)\n",
    "model_svc_pred_smote  = model_svc_smote.predict(X_test)\n",
    "print(confusion_matrix(y_test,model_svc_pred_smote))\n",
    "print(classification_report(y_test,model_svc_pred_smote))\n",
    "confusion_array22 = confusion_matrix(y_test,model_svc_pred_smote)\n",
    "#balance_error_rate29 = (confusion_array29[0][1]/sum(confusion_array29[0])) + ((confusion_array29[1][0])/sum(confusion_array29[1]))\n",
    "\n",
    "#print('balance error rate', balance_error_rate29/2)\n",
    "#as we can"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jay Bhanushali\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV]  C=0.1, gamma=1, kernel=rbf, score=0.5136054421768708, total=   0.8s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.1, gamma=1, kernel=rbf, score=0.5045351473922902, total=   0.8s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    2.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.1, gamma=1, kernel=rbf, score=0.5102272727272728, total=   0.8s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV]  C=0.1, gamma=0.1, kernel=rbf, score=0.518140589569161, total=   0.8s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV]  C=0.1, gamma=0.1, kernel=rbf, score=0.5079365079365079, total=   0.9s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV]  C=0.1, gamma=0.1, kernel=rbf, score=0.5215909090909091, total=   0.9s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV]  C=0.1, gamma=0.01, kernel=rbf, score=0.5113378684807256, total=   0.9s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV]  C=0.1, gamma=0.01, kernel=rbf, score=0.5170068027210885, total=   0.8s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV]  C=0.1, gamma=0.01, kernel=rbf, score=0.5147727272727273, total=   0.9s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV]  C=0.1, gamma=0.001, kernel=rbf, score=0.6077097505668935, total=   0.6s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV]  C=0.1, gamma=0.001, kernel=rbf, score=0.5351473922902494, total=   0.6s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV]  C=0.1, gamma=0.001, kernel=rbf, score=0.5568181818181818, total=   0.6s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV]  C=0.1, gamma=0.0001, kernel=rbf, score=0.6972789115646258, total=   0.6s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV]  C=0.1, gamma=0.0001, kernel=rbf, score=0.800453514739229, total=   0.5s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV]  C=0.1, gamma=0.0001, kernel=rbf, score=0.7863636363636364, total=   0.5s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV]  C=1, gamma=1, kernel=rbf, score=0.528344671201814, total=   0.8s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV]  C=1, gamma=1, kernel=rbf, score=0.518140589569161, total=   0.9s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.525, total=   0.9s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV]  C=1, gamma=0.1, kernel=rbf, score=0.5918367346938775, total=   0.9s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV]  C=1, gamma=0.1, kernel=rbf, score=0.5487528344671202, total=   0.9s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV]  C=1, gamma=0.1, kernel=rbf, score=0.5704545454545454, total=   0.9s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV]  C=1, gamma=0.01, kernel=rbf, score=0.7029478458049887, total=   0.8s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV]  C=1, gamma=0.01, kernel=rbf, score=0.6485260770975056, total=   0.9s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV]  C=1, gamma=0.01, kernel=rbf, score=0.6681818181818182, total=   0.9s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV]  C=1, gamma=0.001, kernel=rbf, score=0.8480725623582767, total=   0.7s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV]  C=1, gamma=0.001, kernel=rbf, score=0.8718820861678005, total=   0.6s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV]  C=1, gamma=0.001, kernel=rbf, score=0.8556818181818182, total=   0.6s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV]  C=1, gamma=0.0001, kernel=rbf, score=0.8424036281179138, total=   0.4s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV]  C=1, gamma=0.0001, kernel=rbf, score=0.8798185941043084, total=   0.4s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV]  C=1, gamma=0.0001, kernel=rbf, score=0.8647727272727272, total=   0.4s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV]  C=10, gamma=1, kernel=rbf, score=0.5317460317460317, total=   0.9s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV]  C=10, gamma=1, kernel=rbf, score=0.518140589569161, total=   0.9s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV]  C=10, gamma=1, kernel=rbf, score=0.5284090909090909, total=   0.9s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV]  C=10, gamma=0.1, kernel=rbf, score=0.6009070294784581, total=   0.9s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV]  C=10, gamma=0.1, kernel=rbf, score=0.5532879818594104, total=   0.9s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV]  C=10, gamma=0.1, kernel=rbf, score=0.5761363636363637, total=   0.9s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV]  C=10, gamma=0.01, kernel=rbf, score=0.7210884353741497, total=   0.9s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV]  C=10, gamma=0.01, kernel=rbf, score=0.6564625850340136, total=   0.9s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV]  C=10, gamma=0.01, kernel=rbf, score=0.6795454545454546, total=   0.9s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV]  C=10, gamma=0.001, kernel=rbf, score=0.8594104308390023, total=   0.6s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV]  C=10, gamma=0.001, kernel=rbf, score=0.8934240362811792, total=   0.7s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV]  C=10, gamma=0.001, kernel=rbf, score=0.8761363636363636, total=   0.6s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV]  C=10, gamma=0.0001, kernel=rbf, score=0.8673469387755102, total=   0.5s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV]  C=10, gamma=0.0001, kernel=rbf, score=0.9070294784580499, total=   0.5s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV]  C=10, gamma=0.0001, kernel=rbf, score=0.8977272727272727, total=   0.5s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV]  C=100, gamma=1, kernel=rbf, score=0.5317460317460317, total=   0.9s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV]  C=100, gamma=1, kernel=rbf, score=0.518140589569161, total=   0.9s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV]  C=100, gamma=1, kernel=rbf, score=0.5284090909090909, total=   0.9s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV]  C=100, gamma=0.1, kernel=rbf, score=0.6009070294784581, total=   0.9s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV]  C=100, gamma=0.1, kernel=rbf, score=0.5532879818594104, total=   0.9s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV]  C=100, gamma=0.1, kernel=rbf, score=0.5761363636363637, total=   0.9s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV]  C=100, gamma=0.01, kernel=rbf, score=0.7210884353741497, total=   0.9s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV]  C=100, gamma=0.01, kernel=rbf, score=0.6564625850340136, total=   0.9s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV]  C=100, gamma=0.01, kernel=rbf, score=0.6795454545454546, total=   0.9s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV]  C=100, gamma=0.001, kernel=rbf, score=0.8594104308390023, total=   0.6s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV]  C=100, gamma=0.001, kernel=rbf, score=0.8934240362811792, total=   0.6s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV]  C=100, gamma=0.001, kernel=rbf, score=0.8761363636363636, total=   0.6s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV]  C=100, gamma=0.0001, kernel=rbf, score=0.8673469387755102, total=   0.5s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=100, gamma=0.0001, kernel=rbf, score=0.9070294784580499, total=   0.6s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV]  C=100, gamma=0.0001, kernel=rbf, score=0.8977272727272727, total=   0.6s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV]  C=1000, gamma=1, kernel=rbf, score=0.5317460317460317, total=   0.9s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV]  C=1000, gamma=1, kernel=rbf, score=0.518140589569161, total=   0.9s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV]  C=1000, gamma=1, kernel=rbf, score=0.5284090909090909, total=   0.9s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV]  C=1000, gamma=0.1, kernel=rbf, score=0.6009070294784581, total=   0.9s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV]  C=1000, gamma=0.1, kernel=rbf, score=0.5532879818594104, total=   0.9s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV]  C=1000, gamma=0.1, kernel=rbf, score=0.5761363636363637, total=   0.9s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV]  C=1000, gamma=0.01, kernel=rbf, score=0.7210884353741497, total=   0.9s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV]  C=1000, gamma=0.01, kernel=rbf, score=0.6564625850340136, total=   0.9s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV]  C=1000, gamma=0.01, kernel=rbf, score=0.6795454545454546, total=   0.9s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV]  C=1000, gamma=0.001, kernel=rbf, score=0.8594104308390023, total=   0.6s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV]  C=1000, gamma=0.001, kernel=rbf, score=0.8934240362811792, total=   0.6s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV]  C=1000, gamma=0.001, kernel=rbf, score=0.8761363636363636, total=   0.6s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV]  C=1000, gamma=0.0001, kernel=rbf, score=0.8673469387755102, total=   0.5s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV]  C=1000, gamma=0.0001, kernel=rbf, score=0.9070294784580499, total=   0.5s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV]  C=1000, gamma=0.0001, kernel=rbf, score=0.8977272727272727, total=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'C': [0.1, 1, 10, 100, 1000], 'gamma': [1, 0.1, 0.01, 0.001, 0.0001], 'kernel': ['rbf']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=3)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#as we can see all are getting identified as one so we need to adjust parameters\n",
    "param_grid_svm = {'C': [0.1,1, 10, 100, 1000], 'gamma': [1,0.1,0.01,0.001,0.0001], 'kernel': ['rbf']} \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_svm = GridSearchCV(SVC(),param_grid_svm,refit=True,verbose=3)\n",
    "grid_svm.fit(X_train_smote,y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_svm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.0001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_svm.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_predictions_svm = grid_svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[491  78]\n",
      " [126  55]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,grid_predictions_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.80      0.86      0.83       569\n",
      "           1       0.41      0.30      0.35       181\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       750\n",
      "   macro avg       0.60      0.58      0.59       750\n",
      "weighted avg       0.70      0.73      0.71       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,grid_predictions_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
